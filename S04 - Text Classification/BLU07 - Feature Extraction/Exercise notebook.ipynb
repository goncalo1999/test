{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12bea12324c032d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gugaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import hashlib # for grading\n",
    "import json\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SKLearn related imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da97614b7076e26a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1 - Price of cars (regex)\n",
    "For the first question, you will be using regex to extract information from the `cars.txt` dataset. In this dataset, you'll find a list of cars that have been sold, as well as their brand, model and selling price.\n",
    "\n",
    "Start by loading the data into a list. The list items are the lines of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e5273236adf54e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "path = \"data/cars.txt\"\n",
    "cars = []\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    cars = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b06a7ac18252021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FORD -- Focus -- 19757',\n",
       " 'LEXUS -- CT 200h -- 392',\n",
       " 'JEEP -- Compass -- 22269',\n",
       " 'CHEVROLET -- Captiva -- 7527',\n",
       " 'SSANGYONG -- REXTON -- 34419',\n",
       " 'TOYOTA -- Prius -- 251',\n",
       " 'BMW -- 535 -- 23521',\n",
       " 'BMW -- 328 -- 13485',\n",
       " 'HYUNDAI -- Sonata -- 2901',\n",
       " 'CHEVROLET -- Volt -- 3293']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32879d17b087c102",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the first item, for example, `FORD` is the brand name, `Focus` is the model, and `19757` is the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-999bbbabdecd84cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1 - Find Toyota cars\n",
    "\n",
    "First, we want to see which `TOYOTA` models have been sold. Find the items in the `cars` list which correspond to cars of the `TOYOTA` brand. Put these items into a list called `ans_1_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d7292940dd0f0b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_1_1 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "ans_1_1 = re.findall(r\"TOYOTA -- [\\w\\s]+ -- \\d+\", str(cars))\n",
    "#First, we want to see which `TOYOTA` models have been sold. Find the items in the `cars` list which correspond to cars of the `TOYOTA` brand. Put these items into a list called `ans_1_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d5ce92d78b9b815",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ans_1_1,list)\n",
    "assert len(ans_1_1) == 111\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(ans_1_1))).encode()).hexdigest() == \\\n",
    "'292f64bf78d500d2bb5dc13ca282edb571f1589b47ce0353f030de70c630608c', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eeeb76b6d1ab67c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2 - Find models with numbers\n",
    "\n",
    "Next, find the items in the `cars` list whose model is a set of numbers instead of characters. For example, `'BMW -- 535 -- 23521'`. Store these items in the list called `ans_1_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dccb1f349ce02a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_1_2 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "ans_1_2 = []\n",
    "pattern = re.compile(r'-- (\\d+) --')\n",
    "\n",
    "for car in cars:\n",
    "\n",
    "    match = pattern.search(car)\n",
    "    if match:\n",
    "        ans_1_2.append(car)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-98c96bad0127da20",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ans_1_2,list)\n",
    "assert len(ans_1_2) == 73\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(ans_1_2))).encode()).hexdigest() == \\\n",
    "'cdee14b87d092c0510a1cb9af05e8b9e96fc6a1c81489f7fd235e4a24e6b9119', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcd2e99fd51f7864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.3 - Selling price bellow 1000\n",
    "\n",
    "Finally, get the car brands and models whose selling price is below 1000.\n",
    "\n",
    "Save the results in the list `ans_1_3`. Each element in this list should be in the format `BRAND -- MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8146ce9f0ba50df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_1_3 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "ans_1_3 = []\n",
    "a = re.findall(r'([A-Za-z\\-]+ -- [\\w\\s\\-]+) -- (\\d+)', str(cars))\n",
    "for car, price in a:\n",
    "    if int(price) < 1000:\n",
    "        ans_1_3.append(str(car))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b746057a51e92a5d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans_1_3) == 77\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(ans_1_3))).encode()).hexdigest() == \\\n",
    "'4d1ef7339260bc7b24f98c0ea6031b4a6fff0f7a9e0100dfde1e17dbbe1308f9', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7271784ba90d3ce9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2 - Job postings\n",
    "The challenge of this exercise notebook is to classify job postings as 'Fake' or 'Real'. In this exercise, we'll be preprocessing the data.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c69e26f590ef0c78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/job_postings.csv', index_col=0).convert_dtypes()\n",
    "\n",
    "X = df['description']\n",
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>Marketeer\r\n",
       " GR, I, Piraeus\r\n",
       " nan\r\n",
       " Social Medi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>English Teacher Abroad \r\n",
       " US, UT, Logan\r\n",
       " nan\r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812</th>\n",
       "      <td>UX Lead\r\n",
       " NZ, N, Masterton\r\n",
       " nan\r\n",
       " nan\r\n",
       " How a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12516</th>\n",
       "      <td>Customer Service  Representative\r\n",
       " US, IA, Cor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>Promotional Sales Representative\r\n",
       " US, OH, Day...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  fraudulent\n",
       "2395   Marketeer\n",
       " GR, I, Piraeus\n",
       " nan\n",
       " Social Medi...           0\n",
       "512    English Teacher Abroad \n",
       " US, UT, Logan\n",
       " nan\n",
       "...           0\n",
       "14812  UX Lead\n",
       " NZ, N, Masterton\n",
       " nan\n",
       " nan\n",
       " How a...           0\n",
       "12516  Customer Service  Representative\n",
       " US, IA, Cor...           0\n",
       "5036   Promotional Sales Representative\n",
       " US, OH, Day...           0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-254c128c0c743d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at an example of a job description and its corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad805151accfbdc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Inside Sales\\r\\n US, CA, Los Angeles\\r\\n 50000-55000\\r\\n GPL Technologies is a solutions provider focused on the design, implementation, and support of high-performance information technology systems.\\xa0 Founded in Los Angeles, California in 2003, we draw on over a decade of expertise as trusted technology advisers, adding value for our customers by offering unique methods of improving IT efficiency, streamlining complex systems and environments, and reducing the costs associated with acquiring and maintaining IT systems.\\xa0GPL cut its teeth serving the intense requirements of customers in the media and entertainment industry. \\xa0We bring that work ethic with us to every customer: time is money, deadlines are non-negotiable, and the show must go on. \\xa0Our company is comprised of creative, independent thinkers with a passion for technology. \\xa0We love big data, fast networks, and solving the problems posed by today's digital media production pipelines.If serving clients who think a quarter petabyte of storage is a starter system sounds like fun to you, or if you love dealing with the dynamic people and personalities in the fast-paced media and entertainment industry, we might be a great fit for each other. \\xa0Send us your resume and lets talk.\\r\\n Want to join an exciting industry and work with cool clients?\\xa0 If you’re a self-starter, professional, energetic and know how to get an appointment then this is the perfect fit!\\xa0We are an IT services firm that caters to some of Hollywood’s most notable Movie Studios, Gaming Companies and Visual Effects Houses. We provide high-performance storage and networking solutions, rendering farms with 2D/3D workflow, editing pipeline integrations and custom software solutions.\\xa0 At the end of the day we are part of what goes into making great movies and leading edge games.\\xa0We are seeking an A-player to join our growing team and be a part of our thriving culture.\\xa0 This is not a job, this is a career with a great compensation plan and long-term professional growth.\\xa0The position is for an Inside Sales Associate.\\xa0 This role requires a person with the ability to manage organized many different requests to be successful; generous compensation and a fulfilling career is the reward.Expected Activities:Work with outside sales to register deals, create quotes and follow up with clients.Work directly with the sales team to ensure that they spend as much time as possible helping clients.Facilitate the proposal development, follow up activities, and other issues related to closing the sale.To be a successful candidate, you should be able to demonstrate your experience and previous achievements.\\xa0 Other factors include communication and presentation skills, computer savvy and industry experience.\\r\\n Sales backgroundComputer Literate\\r\\n Health CareCommissions\\r\\n Full-time\\r\\n Entry level\\r\\n Unspecified\\r\\n Computer Hardware\\r\\n Sales\\r\\n Sales\\r\\n\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cf38bca6e1a69176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10]['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbdc0548dd699460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check the data size and distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-622a8322d87daf24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1913\n",
      "Distribution of classes: {np.int64(0): np.int64(1047), np.int64(1): np.int64(866)}\n"
     ]
    }
   ],
   "source": [
    "def get_data_stats(X, y):\n",
    "    print(f\"Size of dataset: {len(X)}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Distribution of classes: {dict(zip(unique, counts))}\")\n",
    "\n",
    "get_data_stats(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-808b90ccd21d360d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The classes are evenly distributed. We'll use a dev and test set to be able to identify overfitting and check the performance on unseen data.\n",
    "\n",
    "**Note**: So far you've used the `train`/`val`/`test` nomenclature for naming variables related to training, validation and test sets, respectively. `dev` is short for \"development\" and is just another typical identifier for the validation set, and we'll use it throughout this notebook instead of `val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a524119b37972d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1530\n",
      "Dev size: 268\n",
      "Test size: 115\n"
     ]
    }
   ],
   "source": [
    "# train dev test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp)\n",
    "print(f\"Train size: {len(X_train)}\\nDev size: {len(X_dev)}\\nTest size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e93f9088c1da685e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The first step in the workflow is preprocessing which we'll do in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-addc0c904c359402",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.1 - Tokenization\n",
    "\n",
    "Implement the function `apply_tokenizer`. The function should receive a pandas series of text data like `X_train` and an NLTK-style tokenizer. It should return the series with the tokenized text. The tokens of each item in the series should be joined into one string with spaces in between like in the example in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b7930a61806e32",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_tokenizer(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes text data in the provided series using the provided tokenizer.\n",
    "    \n",
    "    E.g. for text data  \"This is a test! No, it can't be\"\n",
    "         it returns \"This is a test ! No , it can ' t be\"\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series with text data\n",
    "    tokenizer - nltk tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return data.apply(lambda x: ' '.join(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f829c5a222c54690",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "X_train_tok = apply_tokenizer(X_train, tokenizer)\n",
    "\n",
    "assert isinstance(X_train_tok, pd.Series), 'The function should return a pandas series.'\n",
    "assert len(X_train_tok) == 1530, 'The length of the series is not correct.'\n",
    "assert isinstance(X_train_tok.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok])).encode()).hexdigest() == \\\n",
    "'0e4a3d7fdab35e43079953d4d1328450b8b36454083f28966e3026e813eb3e3f', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b76d100b971a777f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.2 - Lowercasing\n",
    "\n",
    "In the second step, implement a function that will lowercase the data.  It should take and return a pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee47fb5a45fbd622",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_lowercase(data):\n",
    "    \"\"\"\n",
    "    Lowercases the text data in the provided pandas series.\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return data.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7979e12840663ea2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_tok_lc = apply_lowercase(X_train_tok)\n",
    "\n",
    "assert isinstance(X_train_tok_lc, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc])).encode()).hexdigest() == \\\n",
    "'bd90f00143ed79470e7c4000aa5a800a0c0f68fe0e661eb5ee126fc0d2bb38ac', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8044c14c20583cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.3 - Stopwords\n",
    "\n",
    "Now implement a function that filters the stopwords from the text data. The function should take and return a pandas series. We will use NLTK's built-in English stopword list shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f0dea2c5108c93a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42ecb29c8fe117f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_stopwords(data, stopword_list):\n",
    "    \"\"\"\n",
    "    Removes stopwords from the provided pandas series with text data.\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series\n",
    "    stopword_list - list of stopwords to filter out\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return data.apply(lambda x: ' '.join([word for word in x.split() if word not in stopword_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f70da0255ea6e291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_tok_lc_nosw = apply_filter_stopwords(X_train_tok_lc, stopword_list)\n",
    "\n",
    "assert isinstance (X_train_tok_lc_nosw, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc_nosw) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc_nosw.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc_nosw])).encode()).hexdigest() == \\\n",
    "'13a80f1f4d7740b20cd3e2993ab73d37563212a8b208d3f554646a5783234e87', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d0cb317596faa2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.4 - Punctuation\n",
    "\n",
    "After filtering the stopwords, we want to remove punctuation from the text. Consider only the punctuation characters in `string.punctuation`. Make sure to remove all punctuation and not only tokens that are single punctuation characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0cd3cf5cc97a8f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_punct(data):\n",
    "    \"\"\"\n",
    "    Removes punctuation from the provided pandas series with text data.\n",
    "    \n",
    "    Args:\n",
    "    data - pandas series with text data\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    remove_punct_trans = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    data_filt = data.apply(lambda x: ' '.join(word.translate(remove_punct_trans) for word in x.split()))\n",
    "    \n",
    "    return data_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31c9a6a65413aef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_tok_lc_nosw_nopunct = apply_filter_punct(X_train_tok_lc_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-925e418acc339a2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Normalize whitespaces**\n",
    "\n",
    "Run the following function on `X_train_tok_lc_nosw_nopunct` before checking your answers to remove extra white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67539c50de422305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_whitespace(text):\n",
    "    return re.sub(r\"^\\s+|\\s+$|(?<=\\s)\\s*\", \"\", text)\n",
    "\n",
    "X_train_tok_lc_nosw_nopunct_norm = X_train_tok_lc_nosw_nopunct.apply(normalize_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-650a677a3a01d1bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance (X_train_tok_lc_nosw_nopunct_norm, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc_nosw_nopunct_norm) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc_nosw_nopunct_norm.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc_nosw_nopunct_norm])).encode()).hexdigest() == \\\n",
    "'a8273b9bae9dfb421af75eacc22bfd1b9c809ff36526060d756ffcbbed35dce9', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38d66dd89731e114",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.5 - Stemming\n",
    "\n",
    "The last preprocessing step that you are going to implement is stemming. Implement the function below to receive an NLTK-style stemmer and a pandas series with text data and return the series with the stemmed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a831ba989f3e50e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_stemmer(data, stemmer):\n",
    "    \"\"\"\n",
    "    Stems the text data in the provided pandas series.\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series\n",
    "    stemmer - NLTK-style stemmer\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return data.apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3596a6510ebbda3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "X_train_tok_lc_nosw_nopunct_norm_stem = apply_stemmer(X_train_tok_lc_nosw_nopunct_norm, stemmer)\n",
    "\n",
    "assert isinstance (X_train_tok_lc_nosw_nopunct_norm_stem, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc_nosw_nopunct_norm_stem) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc_nosw_nopunct_norm_stem.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc_nosw_nopunct_norm_stem])).encode()).hexdigest() == \\\n",
    "'fb150190fd6957d636e470fb703db7a353e4d53fcdff4ef131431dac6461a895', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bfe5aed6ebdbb26",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.6 - Everything together\n",
    "\n",
    "Finally, join all the preprocessing steps from above into a transformer that applies the steps in the following order:\n",
    "* tokenization\n",
    "* lowercasing\n",
    "* filtering stopwords\n",
    "* filtering punctuation\n",
    "* normalizing whitespace\n",
    "* stemming.\n",
    "\n",
    "Make use of the functions you designed above and don't forget to initialize all the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea5b2305431c20dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class TextCleanerTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, tokenizer, stopwords, stemmer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stopwords = stopwords\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = apply_tokenizer(X, self.tokenizer)\n",
    "        X = apply_lowercase(X)\n",
    "        X = apply_filter_stopwords(X, self.stopwords)\n",
    "        X = apply_filter_punct(X)\n",
    "        X = X.apply(normalize_whitespace)\n",
    "        X = apply_stemmer(X, self.stemmer)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a4c1aa16cea2ffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text_cleaner = TextCleanerTransformer(\n",
    "    WordPunctTokenizer(),\n",
    "    stopwords=stopwords.words('english'),\n",
    "    stemmer=SnowballStemmer(\"english\"),\n",
    ")\n",
    "\n",
    "X_train_pre = text_cleaner.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4a87d0c9b1f20f7e",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(X_train_pre, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_pre) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_pre.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_pre])).encode()).hexdigest() == \\\n",
    "'fb150190fd6957d636e470fb703db7a353e4d53fcdff4ef131431dac6461a895', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f48abbdab8acc3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3 - Text classification\n",
    "\n",
    "We will now classify the job postings as fake or real. Let's first load the preprocessed data and check the balance of the classes.\n",
    "\n",
    "We are loading the preprocessed csv file here. This way you won't be penalized if you did not finish exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cfef332c9bd3d0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    \"\"\"\n",
    "    Loads a csv file and returns two pandas series, one\n",
    "    the text and one containing the labels\n",
    "    \n",
    "    Args:\n",
    "    file_name: path to input file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_name, index_col = 0)\n",
    "\n",
    "    return df['description'], df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99de6cc5a4a3ff52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre, y_train = load_dataset('data/job_postings_train_preprocessed.csv')\n",
    "X_dev_pre, y_dev = load_dataset('data/job_postings_dev_preprocessed.csv')\n",
    "X_test_pre, y_test = load_dataset('data/job_postings_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfca3c5348fd2262",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1530\n",
      "Distribution of classes: {np.int64(0): np.int64(837), np.int64(1): np.int64(693)}\n"
     ]
    }
   ],
   "source": [
    "get_data_stats(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aaf6fbf5dbc51f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 268\n",
      "Distribution of classes: {np.int64(0): np.int64(147), np.int64(1): np.int64(121)}\n"
     ]
    }
   ],
   "source": [
    "get_data_stats(X_dev_pre, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e5147de37fa0351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So we should be aiming for much better than 45% accuracy, which is what we would get if we naively predicted `1` (fake) for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a844631e7326ff6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.1 - Top N-grams in the BoW vectorization\n",
    "\n",
    "First, we'll look at the top X N-grams in each category to see if anything is interesting. Implement a function that returns the most common N-grams and their count for the given label in the dataset. Use the `CountVectorizer` to create the N-grams. The function should return a list of tuples of the form `(N-gram, count)`, sorted by the `count` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36567f8f392a4836",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_ngrams_for_category(data, labels, filter_label, top_n=10, ngram_size=1):\n",
    "    \"\"\"\n",
    "    Finds the top_n N-grams in the BoW for the given class label.\n",
    "    \n",
    "    Args:\n",
    "    data: pd.Series with text data\n",
    "    labels: class labels for the data\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    top_n: top n N-grams to return\n",
    "    ngram_size: the \"N\" in N-gram (e.g. if ngram_size=2, return only bigrams)\n",
    "    \n",
    "    Returns: list of tuples (N-gram, count)\n",
    "    \"\"\"\n",
    "    # Filter the data based on the given label\n",
    "    filtered_data = data[labels == filter_label]\n",
    "    \n",
    "    # Create the CountVectorizer with the specified ngram_size\n",
    "    vectorizer = CountVectorizer(ngram_range=(ngram_size, ngram_size))\n",
    "    X = vectorizer.fit_transform(filtered_data)\n",
    "    \n",
    "    # Sum up the counts of each n-gram\n",
    "    ngram_counts = X.sum(axis=0).A1\n",
    "    ngram_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Create a list of tuples (N-gram, count) and sort it by count in descending order\n",
    "    ngram_freq = list(zip(ngram_names, ngram_counts))\n",
    "    ngram_freq = sorted(ngram_freq, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ngram_freq[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cca0190cfba4ad83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_10_unigrams_real = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_real == [('nan', 3199),\n",
    "                                ('work', 2689),\n",
    "                                ('experi', 1966),\n",
    "                                ('manag', 1854),\n",
    "                                ('team', 1830),\n",
    "                                ('servic', 1773),\n",
    "                                ('develop', 1706),\n",
    "                                ('custom', 1624),\n",
    "                                ('compani', 1430),\n",
    "                                ('time', 1428)]\n",
    "top_6_unigrams_fake = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=6, ngram_size=1)\n",
    "assert top_6_unigrams_fake == [('nan', 3318),\n",
    "                               ('work', 1828),\n",
    "                               ('manag', 1303),\n",
    "                               ('experi', 1287),\n",
    "                               ('time', 1221),\n",
    "                               ('servic', 1187)]\n",
    "top_5_bigrams_real = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=5, ngram_size=2)\n",
    "assert top_5_bigrams_real == [('nan nan', 1349),\n",
    "                              ('full time', 745),\n",
    "                              ('custom servic', 398),\n",
    "                              ('bachelor degre', 308),\n",
    "                              ('year experi', 211)]\n",
    "top_10_trigrams_fake = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=10, ngram_size=3)\n",
    "assert top_10_trigrams_fake == [('nan nan nan', 851),\n",
    "                                ('nan full time', 165),\n",
    "                                ('time nan nan', 138),\n",
    "                                ('high school equival', 134),\n",
    "                                ('full time nan', 131),\n",
    "                                ('oil gas industri', 123),\n",
    "                                ('time entri level', 116),\n",
    "                                ('full time entri', 104),\n",
    "                                ('level high school', 92),\n",
    "                                ('mid senior level', 89)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05f81b8870270b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Looking at the top ngrams for each category, it doesn't seem like a BoW model will be very interesting, but let's try anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a096ee6776427b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.2 - Modeling pipeline on BoW\n",
    "Let's streamline our pipeline in a nice function. The function should set up the pipeline, fit the pipeline with the train data and predict on the dev data. It should also calculate the accuracy of the prediction and print the classification report.\n",
    "\n",
    "The pipeline should have two steps, vectorization with sklearn `CountVectorizer` and classification with the `LogisticRegression`. Name the pipeline steps `vect` and `clf`. The `CountVectorizer` should take the given `ngram_range` and `max_features` parameter values.\n",
    "\n",
    "The function should return the fitted pipeline, the prediction, and the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af90809e6c74e780",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate(X_train, X_dev, y_train, y_dev, ngram_range=(1,1), max_features=None):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's pipeline and return it along with the predictions and the\n",
    "    accuracy in the validation set. Print the classification report as well.\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed training data\n",
    "    X_dev - preprocessed dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    \n",
    "    Returns:\n",
    "    text_clf - fitted pipeline\n",
    "    y_dev_pred - prediction on the dev data (np.array)\n",
    "    acc - accuracy of the prediction (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(ngram_range=ngram_range, max_features=max_features)),\n",
    "        ('clf', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    text_clf.fit(X_train, y_train)\n",
    "    y_dev_pred = text_clf.predict(X_dev)\n",
    "    acc = accuracy_score(y_dev, y_dev_pred)\n",
    "    \n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    \n",
    "    return text_clf, y_dev_pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-97ba1cceed5a53f9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       147\n",
      "           1       0.86      0.94      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "assert isinstance(clf['vect'], CountVectorizer), 'The pipeline steps are not correct.'\n",
    "assert isinstance(clf['clf'], LogisticRegression), 'The pipeline steps are not correct.'\n",
    "assert hashlib.sha256(json.dumps(''.join([str(i) for i in y_dev_pred])).encode()).hexdigest() == \\\n",
    "'36720a1e3d54d5a2d740cfe8cff6370341459fb18ecfbbddc04e5978ea0e7a7e', 'The prediction is not correct.'\n",
    "np.testing.assert_almost_equal(acc, 0.906, decimal=3, err_msg=\"The accuracy is not correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should look at some misclassified examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7678b7610a7200f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job posting: experienc line cook us sandwich nan belfri inn amp bistro award win b amp b restaur locat sandwich villag cape cod look profession line cook prepar food exact chef specif set station menu success candid play key role contribut custom satisfact acquisit goal look creativ profici cook aspect food prepar posit entitl competit wage plus benefit commensur experi pleas send resum prior menus creat cook avail respons includ set stock station necessari suppliesprepar food servic e g chop veget butcher meat prepar sauc cook menu item cooper rest kitchen staffansw report follow execut sous chef instructionsclean station take care leftov foodstock inventori appropriatelyensur food come simultan high qualiti time fashionmaintain posit profession approach cowork custom 3 year cook experienceexcel understand various cook method ingredi equip proceduresaccuraci speed execut assign tasksfamiliar industri best practic nan full time nan nan restaur custom servic nan\n",
      "Predicted: 1, Actual: 0\n",
      "\n",
      "Job posting: web develop us ca nan nan appli use link url3fd69c66d9c4b82a75b75a28d2ee24a68c44c3daf0041ded92ee685dc326ce31 web develop sportsbusi journal dailysportsbusi journal sportsbusi daili leadingpubl cover sport industri print onlin areseek talent web develop design creat implement andsupport web applic site code compani smission specif busi initi includingindustri lead news coverag confer event distribut sale posit requir quick creativ think abilityto handl multipl project offer opportun learn newskil platform technolog well chanc tosignific influenc compani direct creat newway reach serv reader advertis eventattende key area respons design build new product featur includ cms and commerc platform technolog net 4 0 x html javascript cssdevelop maintain web app support intern systemsimpl third parti first parti apisa need monitor web traffic generat report plusprovid second tier custom support e mail phone train support writer graphic design cmsusersa success candid posit atleast two year profession experi knowledg thefollow area url01a736d89d2f0b19de700923d2c312837e180465650804d0f84105352812bf9a c prefer visual studio ms sqlhtml css 3rd parti javascript librari ajaxcm conceptsaddit experi prefer notrequir nan nan full time nan nan inform technolog servic nan nan\n",
      "Predicted: 0, Actual: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text, pred, true in zip(X_dev_pre[:70], y_dev_pred[:70], y_dev[:70]):\n",
    "    if pred != true:\n",
    "        print(f\"Job posting: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c7cbbc0c3275557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So just with the simplest BoW model we already get an accuracy of 0.9! But let's see if we can do even better... In the misclassified examples, the last one even contains an application url but classified as 'fake'. That's suspicious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4fd66e62c165a4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.3 - Tune hyperparameters\n",
    "Run the function from the previous exercise for different N-gram ranges and/or with different values for max_features. Try to achieve an accuracy higher or equal to 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e75ac8652cc7e741",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       147\n",
      "           1       0.86      0.94      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91       147\n",
      "           1       0.86      0.94      0.90       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.91      0.90       268\n",
      "weighted avg       0.91      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91       147\n",
      "           1       0.86      0.94      0.90       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.91      0.90       268\n",
      "weighted avg       0.91      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       147\n",
      "           1       0.88      0.94      0.91       121\n",
      "\n",
      "    accuracy                           0.92       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.92      0.92      0.92       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       147\n",
      "           1       0.87      0.95      0.91       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.92      0.91       268\n",
      "weighted avg       0.92      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       147\n",
      "           1       0.88      0.95      0.91       121\n",
      "\n",
      "    accuracy                           0.92       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.92      0.92      0.92       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       147\n",
      "           1       0.88      0.95      0.92       121\n",
      "\n",
      "    accuracy                           0.92       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.92      0.92      0.92       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       147\n",
      "           1       0.88      0.95      0.92       121\n",
      "\n",
      "    accuracy                           0.92       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.92      0.92      0.92       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       147\n",
      "           1       0.87      0.95      0.91       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.92      0.91       268\n",
      "weighted avg       0.92      0.91      0.91       268\n",
      "\n",
      "Best accuracy: 0.9216417910447762\n"
     ]
    }
   ],
   "source": [
    "# clf_tuned, y_dev_pred_tuned, acc_tuned = train_and_validate(...)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "max_features_list = [None, 5000, 10000]\n",
    "\n",
    "best_acc = 0\n",
    "best_clf = None\n",
    "best_y_dev_pred = None\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    for max_features in max_features_list:\n",
    "        clf, y_dev_pred, acc = train_and_validate(X_train_pre, X_dev_pre, y_train, y_dev, ngram_range=ngram_range, max_features=max_features)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_clf = clf\n",
    "            best_y_dev_pred = y_dev_pred\n",
    "\n",
    "clf_tuned = best_clf\n",
    "y_dev_pred_tuned = best_y_dev_pred\n",
    "acc_tuned = best_acc\n",
    "\n",
    "print(f\"Best accuracy: {acc_tuned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-722d1b4ff466bdd7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216417910447762\n"
     ]
    }
   ],
   "source": [
    "assert(acc_tuned >= 0.90)\n",
    "print(acc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76675b1b36125145",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dcb6e703b4c8ed64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        63\n",
      "           1       0.86      0.92      0.89        52\n",
      "\n",
      "    accuracy                           0.90       115\n",
      "   macro avg       0.89      0.90      0.90       115\n",
      "weighted avg       0.90      0.90      0.90       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711b6cc0145d445c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! We were able to improve the model a little on the dev set and the performance on the test set is pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28921443e50007c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4 - TF-IDF\n",
    "\n",
    "We will now work with the TF-IDF vectorization of the preprocessed job postings data.\n",
    "\n",
    "### Exercise 4.1 - Manual TF-IDF\n",
    "\n",
    "First, implement a function that manually calculates the TF-IDF vectorization from a dataframe with a Bag of Words vectorization. Here is a reminder of the TF-IDF formula:\n",
    "\n",
    "$$ tf\\text{-}idf(t,d) = tf(t,d) \\times idf(t) = \\frac{n_{td}}{n_d} \\times (log{(\\frac{n+1}{df_t+1})} + 1 )$$\n",
    "\n",
    "where $t$ is the term (word) for which we are calculating the weight, $d$ is the document containing the term, $n_{td}$ is the word count of the term $t$ in document $d$, $n_d$ is the number of words in document $d$, $n$ is the number of documents, and $df_t$ is the number of documents where the term appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b15b82e46b905ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We'll start you off with the BoW representation, in pandas dataframe format\n",
    "vec = CountVectorizer()\n",
    "bow_train = vec.fit_transform(X_train_pre)\n",
    "bow_train_df = pd.DataFrame(bow_train.todense())\n",
    "vocab = vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b915bab713aba13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_tfidf(bow_df):\n",
    "    \"\"\"\n",
    "    Calculates the tfidf vectorization from a BoW vectorization.\n",
    "\n",
    "    Args:\n",
    "    bow_df - dataframe with document word counts (Bag of Words)\n",
    "\n",
    "    Returns:\n",
    "    tfidf - dataframe with the calculated tfidf\n",
    "    \"\"\"\n",
    "    n_docs = bow_df.shape[0]\n",
    "    df = (bow_df > 0).sum(axis=0)\n",
    "    idf = np.log((n_docs + 1) / (df + 1)) + 1\n",
    "    tf = bow_df.div(bow_df.sum(axis=1), axis=0)\n",
    "    tf_idf = tf * idf\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-86090d8867691e1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df = calculate_tfidf(bow_train_df)\n",
    "assert tfidf_df.shape==bow_train_df.shape, 'The shape of the tfidf dataframe is not correct.'\n",
    "assert ((tfidf_df>0).sum()==(bow_train_df>0).sum()).sum()==bow_train_df.shape[1], ''\n",
    "assert hashlib.sha256(json.dumps(''.join([str(round(i,3)) for i in tfidf_df[(tfidf_df>0)].sum().to_numpy()])).encode()).hexdigest() \\\n",
    "== 'cdeee674f9f9449ffb7a1cec047e75a0318af7836d0b94fe3948ce81e1ae4559', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9d199071250b72d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4.2 - Top words in the TF-IDF vectorization\n",
    "\n",
    "Implement a function which returns the top N most important words for the given class in the TF-IDF vectorization, i.e. the words with the highest sum of weights. The function takes the dataframe with the TF-IDF weights calculated in the previous exercise and a vocabulary of words and feature indices from the CountVectorizer and returns a list of the top N most important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00f14b79ff68d32e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_words_for_category_tfidf(data, labels, filter_label, vocab, top_n=10):\n",
    "    \"\"\"\n",
    "    Finds the top_n words in the TF-IDF for the given class label.\n",
    "    \n",
    "    Args:\n",
    "    data: pd.Series with text data\n",
    "    labels: class labels for the data\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    vocab: vocabulary of words and feature indices\n",
    "    top_n: top n ngrams to return\n",
    "    \n",
    "    Returns: list of top-n words\n",
    "    \"\"\"\n",
    "    # Filter the data based on the given label\n",
    "    filtered_data = data[labels == filter_label]\n",
    "    \n",
    "    # Sum the TF-IDF weights for each word\n",
    "    word_sums = filtered_data.sum(axis=0)\n",
    "    \n",
    "    # Get the top N words with the highest sum of weights\n",
    "    top_indices = word_sums.argsort()[-top_n:][::-1]\n",
    "    top_words = [list(vocab.keys())[list(vocab.values()).index(i)] for i in top_indices]\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b51198b450763c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_15_fake = top_words_for_category_tfidf(tfidf_df, y_train, 1, vocab, top_n=15)\n",
    "assert top_15_fake == ['nan',\n",
    "                       'work',\n",
    "                       'time',\n",
    "                       'servic',\n",
    "                       'entri',\n",
    "                       'custom',\n",
    "                       'posit',\n",
    "                       'skill',\n",
    "                       'amp',\n",
    "                       'experi',\n",
    "                       'home',\n",
    "                       'manag',\n",
    "                       'requir',\n",
    "                       'administr',\n",
    "                       'data']\n",
    "top_20_real = top_words_for_category_tfidf(tfidf_df, y_train, 0, vocab, top_n=20)\n",
    "assert top_20_real == ['nan',\n",
    "                       'work',\n",
    "                       'develop',\n",
    "                       'manag',\n",
    "                       'experi',\n",
    "                       'custom',\n",
    "                       'sale',\n",
    "                       'team',\n",
    "                       'servic',\n",
    "                       'product',\n",
    "                       'job',\n",
    "                       'market',\n",
    "                       'client',\n",
    "                       'busi',\n",
    "                       'design',\n",
    "                       'compani',\n",
    "                       'time',\n",
    "                       'technolog',\n",
    "                       'us',\n",
    "                       'engin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2672054e4024a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4.3 - Modeling pipeline on TF-IDF\n",
    "Let's include the TF-IDF features into the pipeline. The function should set up the pipeline, fit the pipeline with the train data and predict on the dev data. It should also calculate the accuracy of the prediction and print the classification report.\n",
    "\n",
    "The pipeline should have three steps: vectorization with sklearn `CountVectorizer`, transformation with sklearn `TfidfTransformer`, and classification with the `LogisticRegression`. Name the pipeline steps `vect`, `tfidf`, and `clf`. The `CountVectorizer` should take the given `ngram_range`, `max_features`, `max_df`, and `min_df` parameter values.\n",
    "\n",
    "The function should return the fitted pipeline, the prediction, and the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02453bb681cd33b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate_with_tfidf(X_train, X_dev, y_train, y_dev, ngram_range=(1,1),\n",
    "                                  max_features=None, max_df=1.0, min_df=1):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's pipeline and return it along with the predictions and the\n",
    "    accuracy in the validation set. Print the classification report as well.\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed training data\n",
    "    X_dev - preprocessed dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    max_df - minimum threshold for document frequency to use in CountVectorizer (int or float)\n",
    "    min_df - maximum threshold for document frequency to use in CountVectorizer (int or float)\n",
    "    \n",
    "    Returns:\n",
    "    text_clf - fitted pipeline\n",
    "    y_dev_pred - prediction on the dev data (np.array)\n",
    "    acc - accuracy of the prediction (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(ngram_range=ngram_range, max_features=max_features, max_df=max_df, min_df=min_df)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    text_clf.fit(X_train, y_train)\n",
    "    y_dev_pred = text_clf.predict(X_dev)\n",
    "    acc = accuracy_score(y_dev, y_dev_pred)\n",
    "    \n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    \n",
    "    return text_clf, y_dev_pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ee1c189fe642928a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.92      0.87      0.89       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tfidf, y_dev_pred_tfidf, acc_tfidf = train_and_validate_with_tfidf(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "assert isinstance(clf_tfidf['vect'], CountVectorizer), 'The pipeline steps are not correct.'\n",
    "assert isinstance(clf_tfidf['tfidf'], TfidfTransformer), 'The pipeline steps are not correct.'\n",
    "assert isinstance(clf_tfidf['clf'], LogisticRegression), 'The pipeline steps are not correct.'\n",
    "assert hashlib.sha256(json.dumps(''.join([str(i) for i in y_dev_pred_tfidf])).encode()).hexdigest() == \\\n",
    "'475ecac8a2c6e2dea9aa06f0105f19aa20ead066339a6398af8d797bfeafbd0a', 'The prediction is not correct.'\n",
    "np.testing.assert_almost_equal(acc_tfidf, 0.906, decimal=3, err_msg=\"The accuracy is not correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we should also look at some misclassified examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87d3359e8827355d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job posting: data entri repres us tx austin 35000 40000 global connect world forc busi rethink communic mobil lifestyl flood technolog econom pressur alway ” mental creat opportun challeng organ size mitel ® nasdaq mitl tsx mnw global leader busi communic easili connect employe partner custom anywher anytim devic smallest busi largest enterpris mitel offer custom maximum choic one industri broadest portfolio best path cloud us 1 billion combin annual revenu 60 million custom worldwid 1 market share western europ mitel clear market leader busi communic respons review detail ticket ensur contain data requir custom monitor bin movement ensur activ seen match paperwork providedwatch contract level vs volum remain bin report discrep qualiti managerprovid ticket copi custom neededansw question custom may specif ticketsadvis plant manag miss paperworkcollect paperwork north south plant review bin inform includ sand pull correct bin bin movement line activ espons review detail ticket ensur contain data requir custom monitor bin movement ensur activ seen match paperwork providedwatch contract level vs volum remain bin report discrep qualiti managerprovid ticket copi custom neededansw question custom may specif ticketsadvis plant manag miss paperworkcollect paperwork north south plant print item scan amarilloreview bin inform includ sand pull correct bin bin movement line activ requir see url1d7626d7c5ba3ff0d31c49d2adda5d517e38070ec37e61c84db213e32cefb616 wqg 1318232t1 99 utmsourc inde amp utmmedium organ amp utmcampaign inde amp id 2129 url7ecc8c08b19f903a44541e4f593f10d4b74fce2e474d104bb1a084463ed14145 high school diplomawork good team full timesalari 35 000 40 000health care dental life insur stock plan option full time associ high school equival consum servic custom servic csr center\n",
      "Predicted: 0, Actual: 1\n",
      "\n",
      "Job posting: experienc line cook us sandwich nan belfri inn amp bistro award win b amp b restaur locat sandwich villag cape cod look profession line cook prepar food exact chef specif set station menu success candid play key role contribut custom satisfact acquisit goal look creativ profici cook aspect food prepar posit entitl competit wage plus benefit commensur experi pleas send resum prior menus creat cook avail respons includ set stock station necessari suppliesprepar food servic e g chop veget butcher meat prepar sauc cook menu item cooper rest kitchen staffansw report follow execut sous chef instructionsclean station take care leftov foodstock inventori appropriatelyensur food come simultan high qualiti time fashionmaintain posit profession approach cowork custom 3 year cook experienceexcel understand various cook method ingredi equip proceduresaccuraci speed execut assign tasksfamiliar industri best practic nan full time nan nan restaur custom servic nan\n",
      "Predicted: 1, Actual: 0\n",
      "\n",
      "Job posting: web develop us ca nan nan appli use link url3fd69c66d9c4b82a75b75a28d2ee24a68c44c3daf0041ded92ee685dc326ce31 web develop sportsbusi journal dailysportsbusi journal sportsbusi daili leadingpubl cover sport industri print onlin areseek talent web develop design creat implement andsupport web applic site code compani smission specif busi initi includingindustri lead news coverag confer event distribut sale posit requir quick creativ think abilityto handl multipl project offer opportun learn newskil platform technolog well chanc tosignific influenc compani direct creat newway reach serv reader advertis eventattende key area respons design build new product featur includ cms and commerc platform technolog net 4 0 x html javascript cssdevelop maintain web app support intern systemsimpl third parti first parti apisa need monitor web traffic generat report plusprovid second tier custom support e mail phone train support writer graphic design cmsusersa success candid posit atleast two year profession experi knowledg thefollow area url01a736d89d2f0b19de700923d2c312837e180465650804d0f84105352812bf9a c prefer visual studio ms sqlhtml css 3rd parti javascript librari ajaxcm conceptsaddit experi prefer notrequir nan nan full time nan nan inform technolog servic nan nan\n",
      "Predicted: 0, Actual: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text, pred, true in zip(X_dev_pre[:70], y_dev_pred_tfidf[:70], y_dev[:70]):\n",
    "    if pred != true:\n",
    "        print(f\"Job posting: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26ada9070ceb8872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Unfortunately, we're still not able to correctly classify those job postings. Let's keep going and see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab54cc6297c36ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 4.4 - Tune hyperparameters again\n",
    "\n",
    "Use the `train_and_validate_with_tfidf` function you created before to train with different hyperparameters and get an accuracy score above 92% on the validation dataset. (This threshold is the same as what we got for the plain CountVectorizer pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07b6f3694941ac8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       147\n",
      "           1       0.94      0.86      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       147\n",
      "           1       0.94      0.85      0.89       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.90       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.92      0.87      0.89       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       147\n",
      "           1       0.91      0.85      0.88       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.89      0.89       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.91       147\n",
      "           1       0.93      0.85      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.91      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       147\n",
      "           1       0.92      0.85      0.88       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       147\n",
      "           1       0.91      0.85      0.88       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.89      0.89       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       147\n",
      "           1       0.91      0.85      0.88       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.89      0.89       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       147\n",
      "           1       0.94      0.85      0.89       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.90       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       147\n",
      "           1       0.94      0.85      0.89       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.90       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       147\n",
      "           1       0.91      0.86      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91       147\n",
      "           1       0.91      0.85      0.88       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.89      0.89       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       147\n",
      "           1       0.94      0.89      0.92       121\n",
      "\n",
      "    accuracy                           0.93       268\n",
      "   macro avg       0.93      0.92      0.92       268\n",
      "weighted avg       0.93      0.93      0.93       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       147\n",
      "           1       0.94      0.88      0.91       121\n",
      "\n",
      "    accuracy                           0.92       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.92      0.92      0.92       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.92      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       147\n",
      "           1       0.93      0.88      0.91       121\n",
      "\n",
      "    accuracy                           0.92       268\n",
      "   macro avg       0.92      0.91      0.92       268\n",
      "weighted avg       0.92      0.92      0.92       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       147\n",
      "           1       0.92      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.92      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       147\n",
      "           1       0.92      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.92      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       147\n",
      "           1       0.89      0.88      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       147\n",
      "           1       0.88      0.88      0.88       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.89      0.89      0.89       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       147\n",
      "           1       0.92      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.92      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       147\n",
      "           1       0.92      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.92      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       147\n",
      "           1       0.90      0.88      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       147\n",
      "           1       0.90      0.88      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       147\n",
      "           1       0.95      0.91      0.93       121\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.94      0.93      0.94       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       147\n",
      "           1       0.95      0.89      0.92       121\n",
      "\n",
      "    accuracy                           0.93       268\n",
      "   macro avg       0.93      0.93      0.93       268\n",
      "weighted avg       0.93      0.93      0.93       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       147\n",
      "           1       0.92      0.91      0.92       121\n",
      "\n",
      "    accuracy                           0.93       268\n",
      "   macro avg       0.93      0.92      0.92       268\n",
      "weighted avg       0.93      0.93      0.93       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       147\n",
      "           1       0.95      0.89      0.92       121\n",
      "\n",
      "    accuracy                           0.93       268\n",
      "   macro avg       0.93      0.93      0.93       268\n",
      "weighted avg       0.93      0.93      0.93       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       147\n",
      "           1       0.91      0.89      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       147\n",
      "           1       0.91      0.89      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       147\n",
      "           1       0.89      0.89      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       147\n",
      "           1       0.89      0.89      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       147\n",
      "           1       0.92      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.92      0.91      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       147\n",
      "           1       0.91      0.88      0.89       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       147\n",
      "           1       0.91      0.88      0.90       121\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.91      0.90      0.91       268\n",
      "weighted avg       0.91      0.91      0.91       268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       147\n",
      "           1       0.90      0.88      0.89       121\n",
      "\n",
      "    accuracy                           0.90       268\n",
      "   macro avg       0.90      0.90      0.90       268\n",
      "weighted avg       0.90      0.90      0.90       268\n",
      "\n",
      "Best accuracy with TF-IDF: 0.9365671641791045\n"
     ]
    }
   ],
   "source": [
    "# clf_tfidf_tuned, y_dev_pred_tfidf_tuned, acc_tfidf_tuned = train_and_validate_with_tfidf(...)\n",
    "# YOUR CODE HERE\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "max_features_list = [None, 5000, 10000]\n",
    "max_df_list = [0.75, 1.0]\n",
    "min_df_list = [1, 2]\n",
    "\n",
    "best_acc_tfidf = 0\n",
    "best_clf_tfidf = None\n",
    "best_y_dev_pred_tfidf = None\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "\tfor max_features in max_features_list:\n",
    "\t\tfor max_df in max_df_list:\n",
    "\t\t\tfor min_df in min_df_list:\n",
    "\t\t\t\tclf_tfidf, y_dev_pred_tfidf, acc_tfidf = train_and_validate_with_tfidf(\n",
    "\t\t\t\t\tX_train_pre, X_dev_pre, y_train, y_dev,\n",
    "\t\t\t\t\tngram_range=ngram_range, max_features=max_features,\n",
    "\t\t\t\t\tmax_df=max_df, min_df=min_df\n",
    "\t\t\t\t)\n",
    "\t\t\t\tif acc_tfidf > best_acc_tfidf:\n",
    "\t\t\t\t\tbest_acc_tfidf = acc_tfidf\n",
    "\t\t\t\t\tbest_clf_tfidf = clf_tfidf\n",
    "\t\t\t\t\tbest_y_dev_pred_tfidf = y_dev_pred_tfidf\n",
    "\n",
    "clf_tfidf_tuned = best_clf_tfidf\n",
    "y_dev_pred_tfidf_tuned = best_y_dev_pred_tfidf\n",
    "acc_tfidf_tuned = best_acc_tfidf\n",
    "\n",
    "print(f\"Best accuracy with TF-IDF: {acc_tfidf_tuned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-07b6f3694941ac81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365671641791045\n"
     ]
    }
   ],
   "source": [
    "assert(acc_tfidf_tuned > 0.92)\n",
    "print(acc_tfidf_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-123f82e6058cdcdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5352a2d0b2f2903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.83        63\n",
      "           1       0.96      0.52      0.68        52\n",
      "\n",
      "    accuracy                           0.77       115\n",
      "   macro avg       0.84      0.75      0.75       115\n",
      "weighted avg       0.83      0.77      0.76       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf_tfidf_tuned.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the performace on the test set improve against the pure BoW pipeline? If not, the pipeline might require more tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations to mastering the first NLP unit! This was no easy task, be proud of yourself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_s03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
